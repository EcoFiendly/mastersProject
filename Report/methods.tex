\subsection{Dataset}

The IUCN Red List assessments text data was downloaded (December 2020) from The IUCN Red List of Threatened Species\textsuperscript{TM} website \parencite{iucn2021}. Each row represents one entry of information for one species. The information of interest are as follows (detailed information available on their website):
\begin{itemize}
    \item The red list category lists the assigned category for the species. 
    \item The rationale, a summarised justification for the category assigned. 
    \item The habitat describes the general habitat use and ecology. 
    \item A subcategory of habitat is systems, which are the terrestrial, marine and freshwater (or different combinations of) habitats.
    \item Realm lists the biogeographic realms (individual or a combination of up to seven) that correspond to the habitat locations
    \item Threats lists and describes the general and specific threats that are affecting the species. 
    \item Population describes population numbers, structure and current population trend. 
    \item Range lists and describes the historical and current geographic range, and includes the estimated aera of occupancy (AOO) and estimated extent of occurrence (EOO). 
    \item Use and trade describes the details of how the species are used and/or traded.
    \item Conservation actions describes the current and recommended general and specific actions in place to protect to species. 
\end{itemize}

\subsection{Data preprocessing and corpus construction}

Figure (Corpus is collection of documents, and documents is collection of tokens) shows the structure of the data. 

The texts were first processed and normalised. Global assessments in English were selected. Texts were cleaned using regular expressions to remove noise. The texts were then processed using spaCy \parencite{spacy}, where stop words were removed, remaining words were lemmatised and tokenised, producing a bag of words (BoW) model output. The phraser module from Gensim \parencite{rehurek_lrec} was then applied onto the BoW to detect and generate bigrams. Finally, a dictionary (vocabulary) of the tokens was created, where tokens which appear outside of 1\% and 50\% documents were filtered out. 

\subsection{Topic analyses}

Latent Dirichlet Allocation \parencite{blei2003latent}, a type of topic model under the class of unsupervised machine learning, was applied onto the corpus. The models were ran for number of topics ranging from 2 to 100, and their performance was measured using topic coherence as a metric \parencite{roder2015exploring}. On top of the computed metrics, I inspected the topic space that was visualised using pyLDAvis (a python port of LDAvis \parencite{sievert2014ldavis}). The model selection suggested 17 topics as the optimal number for this corpus. The labels and top 16 words for each topic are shown in table . Analysis steps are summarised in Fig .

(insert graphical model representation of LDA and describe)

\textit{Figure . Summary of analysis steps of the LDA model. (a) Data preprocessing shows the structure of the dataset (text justifications for the risk category assigned to species) and the methods applied  to it (each text summary is reduced to word frequencies then very rare and very common words were filtered out). (b) The example topic model calculates the word composition for each topic. The model is then applied to a piece of text to generate the topic composition of the text. Topics are named to best describe the top} n \textit{words associated with the topic.}

(insert table to show topic number, topic name and words in topic)

Table . Topics revealed from applying a LDA model on the IUCN Red List corpus.

% need help with phrasing:
Using the trained model, topic compositions for each of the texts were calculated. These were then added and normalised to produce an overall topic composition for each species.


