\subsection{Dataset}

The IUCN Red List AST data was downloaded (December 2020) and the spatial data for mammalian species were downloaded (June 2021) from The IUCN Red List of Threatened Species\textsuperscript{TM} website \parencite{iucn2021}. The AST data contains a large amount of information, and my analysis focuses on a subset of the data which are sentences or paragraphs of text, listed in table \Cref{tab:example and desc of data}.

\begin{table}[hbtp]
    \centering
    \tiny
        \begin{tabulary}{1.0\textwidth}{|L|L|L|L|L|L|L|L|L|}
        \hline
        \multicolumn{2}{|c|}{\textbf{Metadata}} & \multicolumn{7}{c|}{\textbf{Text data to be preprocessed}}\\
        \hline
        Red List Category & Systems & Rationale & Habitat & Threats & Population & Range & Use and trade & Conservation actions\\
        \hline
        Lists the assigned category for the species & Terrestrial, marine and freshwater (or combinations of the three) & Summary of the text justification for the category assigned & General habitat use and ecology & General and specific threats that are affecting the species & Population numbers, structure and current population trend & Historical and current geographic range & How species are used and/or traded & Current and recommended general and specific actions in place to protect the species\\
        \hline
        \end{tabulary}
    \small
    \caption{Example and description of the data used in my analysis (see \parencite{iucn2021}). The first two columns are metadata that will be later used to group the results from the model. The next seven columns are text data that will be preprocessed and used to train the model to reveal the "topics". Each row of information represents the data collected by the IUCN for a single species. Each of the entries in the last seven columns is equivalent to one document (LDA terminology)}
    \label{tab:example and desc of data}
\end{table}

\subsection{Data preprocessing}

The texts were processed in multiple steps. Only global assessments in English were selected. This removes noise from regional assessments and assessments not recorded in English. Texts were then cleaned using regular expressions. The texts were then processed using spaCy \parencite{spacy}, where stop words were removed, remaining words were lemmatised and tokenised, producing a bag of words (BoW) matrix. The phraser module from Gensim \parencite{rehurek_lrec} was then applied onto the BoW to detect and generate bigrams (pairs words that when occurring together could have a different meaning, e.g., global and warming forming global warming). Finally, a dictionary (vocabulary) of the tokens (words or bigrams) was created. Tokens that appeared in less than 1\% or more than 50\% of documents were filtered out for being too rare or common and thus uninformative. The threshold of tokens appearing in more 50\% was selected as this study is looking for latent themes.

\subsection{Model, terminology and selection}

Latent Dirichlet Allocation (LDA) \parencite{blei2003latent} was used to perform the topic analysis. LDA is a type of generative probabilistic model under the class of unsupervised machine learning. LDA is able to reduce the dimensionality of large amounts of text data, and identify \textit{"topics"} from within based on words that are statistically associated. The algorithm estimates, for a given number \textit{k} of topics, the probability of each word belonging to each topic, and the probability of a word from a document belonging to a topic. This means that the algorithm assumes that each document is generated by a collection of topics and topics contain keywords that occur together often. We can then infer what the document is about from the topics that are discovered by the model.

The basic unit is a word or bigram (or token) which is present in the constructed dictionary (preprocessing step); a document is made up of any number of words; a corpus is a collection of any number of documents \parencite{blei2003latent}. In relation to my dataset, the corpus is the collection of all the text data from the last seven columns in \Cref{tab:example and desc of data}, and each entry from the seven sections is a document, and is made up of a number of words. As such, each species would comprise of seven documents, and the length of the corpus is number of species multiplied by seven.

Models were trained with the number of topics ranging from 2 to 100 using the prepared corpus. Their performance was measured using topic coherence as a metric \parencite{roder2015exploring}. On top of the computed metrics (\Cref{fig:cv plot}), I inspected the topic space that was visualised using pyLDAvis (a python port of LDAvis \parencite{sievert2014ldavis}). The model selection suggested 17 topics as the optimal number for this corpus. The labels and top 16 words for each topic are shown in \Cref{tab:topic label and top 16 words}.

Using the selected model, topic compositions for each of the documents were calculated. Topics can have a non-zero probability of being discovered for every document, thus not all of the topics in each document will neccessarily be informative, especially when the probibility is very small. In order to focus on the topics that are informative, the topic probabilities were plotted against their probability density (\Cref{fig:kde plot}). This revealed that a threshold of 1/17 was suitable for deciding if a document was about that topic, where probabilities below the threshold were masked to zero.

I calculated the intertopic distance using four different distance measures Kullback-Leibler divergence, Hellinger distance, Jaccard Index and Jensen-Shannon divergence. Ward's linkage \parencite{ward1963hierarchical}, a hierarchical clustering technique, was then applied on the four different measure outputs to minimise the topic distances and cluster the topics accordingly (\Cref{fig:dendrograms}). I selected the cluster generated from the Jaccard's index (\Cref{fig:topic heatmap}) after visually comparing the different clusters by plotting them onto dendrograms. 

Due to the nature of LDA, words can be and were assigned to multiple topics, e.g. the word threat was found in six different topics. This is a limitation of LDA, and results from the model selection. If there are too few topics, the topics themselves might not provide a clear meaning. However, if there are too many topics, it could result in many junk topics and only a smaller numbr of topics that will be useful.

\subsection{Aggregating the data by IUCN metadata}
The document probabilities were aggregated for every species. These were then grouped in four different ways to produce heatmaps of the topic probabilities to each of the groups. The first three groups are the seven sections, Red List category and Systems, which are IUCN metadata, and the fourth is taxonomic class from the IUCN.

\subsection{Mapping topics to mammalian species range}

The analysis is further expanded by mapping topics to mammalian species range. I selected the mammalian species range to start with because of the focus of literature on mammals \parencite{cardillo2008predictability,gonzalez2013intrinsic,purvis2000predicting} compared to other species such as plants \parencite{stefanaki2015lessons,powney2014phylogenetically,sodhi2008correlates} and invertebrates \parencite{arbetman2017global,koh2004ecological,sullivan2000comparative}. These are mammalian range data obtained from the IUCN, and does not contain every mammalian species. Using the previous threshold of 1/17, the topic probabilities were converted to presence and absence values represented by 1 and 0. These values were then summed and averaged to determine the ratio of mammalian species with the topic present to the total number of mammalian species present at each pixel. For example, if there are 15 species present on a particular pixel, and only three of them have a topic present, the ratio would be 1/5 at that pixel.
